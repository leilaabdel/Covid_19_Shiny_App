{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2.0-la-tj-ak-ensemble_baseline_predictions.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leilaabdel/Covid_19_Shiny_App/blob/master/notebooks/2.0-la-tj-ak-ensemble-baseline-predictions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rWTS99OI8l-",
        "colab_type": "text"
      },
      "source": [
        "## Video Sentiment Analysis in the Wild\n",
        "### Ensembling Notebook | CS231n\n",
        "\n",
        "This notebook preprocesses input videos to extract faces, frames, poses, and audio before running pre-trained models for each modality to predict group sentiment (positive, negative, or neutral). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58avLN7UlDDA",
        "colab_type": "code",
        "outputId": "a507d631-faf9-417f-a5a4-2f457c0651d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "# Clone the code base\n",
        "!git clone 'https://github.com/kevincong95/cs231n-emotiw.git'\n",
        "\n",
        "\n",
        "# Install required packages \n",
        "!pip install -r  '/content/cs231n-emotiw/requirements-predictions.txt'\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'cs231n-emotiw'...\n",
            "remote: Enumerating objects: 193, done.\u001b[K\n",
            "remote: Counting objects: 100% (193/193), done.\u001b[K\n",
            "remote: Compressing objects: 100% (145/145), done.\u001b[K\n",
            "remote: Total 447 (delta 102), reused 124 (delta 47), pack-reused 254\u001b[K\n",
            "Receiving objects: 100% (447/447), 173.19 MiB | 38.11 MiB/s, done.\n",
            "Resolving deltas: 100% (235/235), done.\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (from -r /content/cs231n-emotiw/requirements-predictions.txt (line 1)) (2.2.0)\n",
            "Requirement already satisfied: opencv-python>=4.0 in /usr/local/lib/python3.6/dist-packages (from -r /content/cs231n-emotiw/requirements-predictions.txt (line 2)) (4.1.2.30)\n",
            "Collecting pydub==0.24.0\n",
            "  Downloading https://files.pythonhosted.org/packages/ba/f9/2cd255898c11179a57415937d601ab1e8a14a7c6a8331ff9c365e97e41f6/pydub-0.24.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from -r /content/cs231n-emotiw/requirements-predictions.txt (line 4)) (3.2.1)\n",
            "Collecting moviepy>=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/54/01a8c4e35c75ca9724d19a7e4de9dc23f0ceb8769102c7de056113af61c3/moviepy-1.0.3.tar.gz (388kB)\n",
            "\u001b[K     |████████████████████████████████| 389kB 7.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: audioread in /usr/local/lib/python3.6/dist-packages (from -r /content/cs231n-emotiw/requirements-predictions.txt (line 6)) (2.1.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from -r /content/cs231n-emotiw/requirements-predictions.txt (line 7)) (1.0.3)\n",
            "Requirement already satisfied: glob2 in /usr/local/lib/python3.6/dist-packages (from -r /content/cs231n-emotiw/requirements-predictions.txt (line 8)) (0.7)\n",
            "Collecting argparse\n",
            "  Downloading https://files.pythonhosted.org/packages/f2/94/3af39d34be01a24a6e65433d19e107099374224905f1e0cc6bbe1fd22a2f/argparse-1.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from -r /content/cs231n-emotiw/requirements-predictions.txt (line 11)) (1.18.4)\n",
            "Collecting openl3\n",
            "  Downloading https://files.pythonhosted.org/packages/e2/88/8536723b81c47ada614d008a75e71923932f22e35ab89d4bf5fe441b58fc/openl3-0.3.1.tar.gz\n",
            "Collecting SoundFile\n",
            "  Downloading https://files.pythonhosted.org/packages/eb/f2/3cbbbf3b96fb9fa91582c438b574cff3f45b29c772f94c400e2c99ef5db9/SoundFile-0.10.3.post1-py2.py3-none-any.whl\n",
            "Collecting imgaug<0.2.7,>=0.2.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/2e/748dbb7bb52ec8667098bae9b585f448569ae520031932687761165419a2/imgaug-0.2.6.tar.gz (631kB)\n",
            "\u001b[K     |████████████████████████████████| 634kB 13.3MB/s \n",
            "\u001b[?25hCollecting face_recognition\n",
            "  Downloading https://files.pythonhosted.org/packages/1e/95/f6c9330f54ab07bfa032bf3715c12455a381083125d8880c43cbe76bb3d0/face_recognition-1.3.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: dlib in /usr/local/lib/python3.6/dist-packages (from -r /content/cs231n-emotiw/requirements-predictions.txt (line 16)) (19.18.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow->-r /content/cs231n-emotiw/requirements-predictions.txt (line 1)) (0.34.2)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow->-r /content/cs231n-emotiw/requirements-predictions.txt (line 1)) (0.3.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->-r /content/cs231n-emotiw/requirements-predictions.txt (line 1)) (1.1.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->-r /content/cs231n-emotiw/requirements-predictions.txt (line 1)) (1.12.0)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->-r /content/cs231n-emotiw/requirements-predictions.txt (line 1)) (2.10.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow->-r /content/cs231n-emotiw/requirements-predictions.txt (line 1)) (1.29.0)\n",
            "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->-r /content/cs231n-emotiw/requirements-predictions.txt (line 1)) (2.2.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow->-r /content/cs231n-emotiw/requirements-predictions.txt (line 1)) (0.2.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow->-r /content/cs231n-emotiw/requirements-predictions.txt (line 1)) (1.6.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->-r /content/cs231n-emotiw/requirements-predictions.txt (line 1)) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->-r /content/cs231n-emotiw/requirements-predictions.txt (line 1)) (0.9.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow->-r /content/cs231n-emotiw/requirements-predictions.txt (line 1)) (1.12.1)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow->-r /content/cs231n-emotiw/requirements-predictions.txt (line 1)) (1.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow->-r /content/cs231n-emotiw/requirements-predictions.txt (line 1)) (3.2.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->-r /content/cs231n-emotiw/requirements-predictions.txt (line 1)) (2.2.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->-r /content/cs231n-emotiw/requirements-predictions.txt (line 1)) (3.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r /content/cs231n-emotiw/requirements-predictions.txt (line 4)) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r /content/cs231n-emotiw/requirements-predictions.txt (line 4)) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r /content/cs231n-emotiw/requirements-predictions.txt (line 4)) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r /content/cs231n-emotiw/requirements-predictions.txt (line 4)) (0.10.0)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.6/dist-packages (from moviepy>=1.0.0->-r /content/cs231n-emotiw/requirements-predictions.txt (line 5)) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.6/dist-packages (from moviepy>=1.0.0->-r /content/cs231n-emotiw/requirements-predictions.txt (line 5)) (4.41.1)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.6/dist-packages (from moviepy>=1.0.0->-r /content/cs231n-emotiw/requirements-predictions.txt (line 5)) (2.23.0)\n",
            "Collecting proglog<=1.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/fe/ab/4cb19b578e1364c0b2d6efd6521a8b4b4e5c4ae6528041d31a2a951dd991/proglog-0.1.9.tar.gz\n",
            "Collecting imageio<3.0,>=2.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/2b/9dd19644f871b10f7e32eb2dbd6b45149c350b4d5f2893e091b882e03ab7/imageio-2.8.0-py3-none-any.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 22.8MB/s \n",
            "\u001b[?25hCollecting imageio_ffmpeg>=0.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/df/c8/04c6b4a001b8ae7326fb83d6665af1ee58d6cc1acb421f8ea40d2678fe3c/imageio_ffmpeg-0.4.2-py3-none-manylinux2010_x86_64.whl (26.9MB)\n",
            "\u001b[K     |████████████████████████████████| 26.9MB 90kB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->-r /content/cs231n-emotiw/requirements-predictions.txt (line 7)) (2018.9)\n",
            "Collecting keras<2.3.0,>=2.0.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/ba/2d058dcf1b85b9c212cc58264c98a4a7dd92c989b798823cc5690d062bb2/Keras-2.2.5-py2.py3-none-any.whl (336kB)\n",
            "\u001b[K     |████████████████████████████████| 337kB 42.3MB/s \n",
            "\u001b[?25hCollecting kapre==0.1.4\n",
            "  Downloading https://files.pythonhosted.org/packages/3f/2e/f540d1d1f05c764686163fdb5bb1e5c703f1528076d2829bfc3900683f06/kapre-0.1.4-py3-none-any.whl\n",
            "Collecting PySoundFile>=0.9.0.post1\n",
            "  Downloading https://files.pythonhosted.org/packages/2a/b3/0b871e5fd31b9a8e54b4ee359384e705a1ca1e2870706d2f081dc7cc1693/PySoundFile-0.9.0.post1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: resampy<0.3.0,>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from openl3->-r /content/cs231n-emotiw/requirements-predictions.txt (line 12)) (0.2.2)\n",
            "Collecting scikit-image<0.15.0,>=0.14.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/78/cfb15cdb3f63eea16946a42d0dbf7ef17be79d30858aa8efd5f6757bd106/scikit_image-0.14.5-cp36-cp36m-manylinux1_x86_64.whl (25.4MB)\n",
            "\u001b[K     |████████████████████████████████| 25.4MB 95kB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.6/dist-packages (from SoundFile->-r /content/cs231n-emotiw/requirements-predictions.txt (line 13)) (1.14.0)\n",
            "Collecting face-recognition-models>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cf/3b/4fd8c534f6c0d1b80ce0973d01331525538045084c73c153ee6df20224cf/face_recognition_models-0.3.0.tar.gz (100.1MB)\n",
            "\u001b[K     |████████████████████████████████| 100.2MB 63kB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from face_recognition->-r /content/cs231n-emotiw/requirements-predictions.txt (line 15)) (7.0.0)\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.6/dist-packages (from face_recognition->-r /content/cs231n-emotiw/requirements-predictions.txt (line 15)) (7.1.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->-r /content/cs231n-emotiw/requirements-predictions.txt (line 1)) (3.2.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->-r /content/cs231n-emotiw/requirements-predictions.txt (line 1)) (1.6.0.post3)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->-r /content/cs231n-emotiw/requirements-predictions.txt (line 1)) (1.7.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->-r /content/cs231n-emotiw/requirements-predictions.txt (line 1)) (46.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->-r /content/cs231n-emotiw/requirements-predictions.txt (line 1)) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->-r /content/cs231n-emotiw/requirements-predictions.txt (line 1)) (0.4.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0,>=2.8.1->moviepy>=1.0.0->-r /content/cs231n-emotiw/requirements-predictions.txt (line 5)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0,>=2.8.1->moviepy>=1.0.0->-r /content/cs231n-emotiw/requirements-predictions.txt (line 5)) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0,>=2.8.1->moviepy>=1.0.0->-r /content/cs231n-emotiw/requirements-predictions.txt (line 5)) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0,>=2.8.1->moviepy>=1.0.0->-r /content/cs231n-emotiw/requirements-predictions.txt (line 5)) (3.0.4)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from keras<2.3.0,>=2.0.9->openl3->-r /content/cs231n-emotiw/requirements-predictions.txt (line 12)) (1.0.8)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras<2.3.0,>=2.0.9->openl3->-r /content/cs231n-emotiw/requirements-predictions.txt (line 12)) (3.13)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from kapre==0.1.4->openl3->-r /content/cs231n-emotiw/requirements-predictions.txt (line 12)) (0.16.0)\n",
            "Requirement already satisfied: librosa>=0.5 in /usr/local/lib/python3.6/dist-packages (from kapre==0.1.4->openl3->-r /content/cs231n-emotiw/requirements-predictions.txt (line 12)) (0.6.3)\n",
            "Requirement already satisfied: numba>=0.32 in /usr/local/lib/python3.6/dist-packages (from resampy<0.3.0,>=0.2.1->openl3->-r /content/cs231n-emotiw/requirements-predictions.txt (line 12)) (0.48.0)\n",
            "Requirement already satisfied: networkx>=1.8 in /usr/local/lib/python3.6/dist-packages (from scikit-image<0.15.0,>=0.14.3->openl3->-r /content/cs231n-emotiw/requirements-predictions.txt (line 12)) (2.4)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image<0.15.0,>=0.14.3->openl3->-r /content/cs231n-emotiw/requirements-predictions.txt (line 12)) (1.1.1)\n",
            "Requirement already satisfied: cloudpickle>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image<0.15.0,>=0.14.3->openl3->-r /content/cs231n-emotiw/requirements-predictions.txt (line 12)) (1.3.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0->SoundFile->-r /content/cs231n-emotiw/requirements-predictions.txt (line 13)) (2.20)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow->-r /content/cs231n-emotiw/requirements-predictions.txt (line 1)) (1.6.0)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow->-r /content/cs231n-emotiw/requirements-predictions.txt (line 1)) (4.0)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow->-r /content/cs231n-emotiw/requirements-predictions.txt (line 1)) (3.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow->-r /content/cs231n-emotiw/requirements-predictions.txt (line 1)) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow->-r /content/cs231n-emotiw/requirements-predictions.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa>=0.5->kapre==0.1.4->openl3->-r /content/cs231n-emotiw/requirements-predictions.txt (line 12)) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.6/dist-packages (from librosa>=0.5->kapre==0.1.4->openl3->-r /content/cs231n-emotiw/requirements-predictions.txt (line 12)) (0.15.1)\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.32->resampy<0.3.0,>=0.2.1->openl3->-r /content/cs231n-emotiw/requirements-predictions.txt (line 12)) (0.31.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow->-r /content/cs231n-emotiw/requirements-predictions.txt (line 1)) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow->-r /content/cs231n-emotiw/requirements-predictions.txt (line 1)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow->-r /content/cs231n-emotiw/requirements-predictions.txt (line 1)) (3.1.0)\n",
            "Building wheels for collected packages: moviepy, openl3, imgaug, proglog, face-recognition-models\n",
            "  Building wheel for moviepy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for moviepy: filename=moviepy-1.0.3-cp36-none-any.whl size=110728 sha256=2eda87a764b2f28e3061689eab01a8f65e47b2bb6736e10b8992644c1bf5d932\n",
            "  Stored in directory: /root/.cache/pip/wheels/e0/fe/1c/f4e6dca9e828d4b979c04e461d7fcc5b8e7bd35f947e665b65\n",
            "  Building wheel for openl3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openl3: filename=openl3-0.3.1-py2.py3-none-any.whl size=249323247 sha256=ae265bc1507f403710d29f0510735281d41dce1f90b017ccf597d58acf32d380\n",
            "  Stored in directory: /root/.cache/pip/wheels/13/63/c9/35868f3dd3b466909e73178db8566430da2d093cc055b932b1\n",
            "  Building wheel for imgaug (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for imgaug: filename=imgaug-0.2.6-cp36-none-any.whl size=654020 sha256=c9d8c33c68bfde3f847ac744a70bb2328168565bc114404431af1d395c07f3d4\n",
            "  Stored in directory: /root/.cache/pip/wheels/97/ec/48/0d25896c417b715af6236dbcef8f0bed136a1a5e52972fc6d0\n",
            "  Building wheel for proglog (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for proglog: filename=proglog-0.1.9-cp36-none-any.whl size=6149 sha256=f9dfbb27a68a79fb93193e1b52f420325105a40556792c00fb1e5dafdf4d2d9f\n",
            "  Stored in directory: /root/.cache/pip/wheels/65/56/60/1d0306a8d90b188af393c1812ddb502a8821b70917f82dcc00\n",
            "  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566172 sha256=59e6b9e8a3e59a66b5d4288d257b6f0bc053885c19deb10e8844d5a48eda3790\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/99/18/59c6c8f01e39810415c0e63f5bede7d83dfb0ffc039865465f\n",
            "Successfully built moviepy openl3 imgaug proglog face-recognition-models\n",
            "Installing collected packages: pydub, proglog, imageio, imageio-ffmpeg, moviepy, argparse, keras, kapre, PySoundFile, scikit-image, openl3, SoundFile, imgaug, face-recognition-models, face-recognition\n",
            "  Found existing installation: imageio 2.4.1\n",
            "    Uninstalling imageio-2.4.1:\n",
            "      Successfully uninstalled imageio-2.4.1\n",
            "  Found existing installation: moviepy 0.2.3.5\n",
            "    Uninstalling moviepy-0.2.3.5:\n",
            "      Successfully uninstalled moviepy-0.2.3.5\n",
            "  Found existing installation: Keras 2.3.1\n",
            "    Uninstalling Keras-2.3.1:\n",
            "      Successfully uninstalled Keras-2.3.1\n",
            "  Found existing installation: kapre 0.1.3.1\n",
            "    Uninstalling kapre-0.1.3.1:\n",
            "      Successfully uninstalled kapre-0.1.3.1\n",
            "  Found existing installation: scikit-image 0.16.2\n",
            "    Uninstalling scikit-image-0.16.2:\n",
            "      Successfully uninstalled scikit-image-0.16.2\n",
            "  Found existing installation: imgaug 0.2.9\n",
            "    Uninstalling imgaug-0.2.9:\n",
            "      Successfully uninstalled imgaug-0.2.9\n",
            "Successfully installed PySoundFile-0.9.0.post1 SoundFile-0.10.3.post1 argparse-1.4.0 face-recognition-1.3.0 face-recognition-models-0.3.0 imageio-2.8.0 imageio-ffmpeg-0.4.2 imgaug-0.2.6 kapre-0.1.4 keras-2.2.5 moviepy-1.0.3 openl3-0.3.1 proglog-0.1.9 pydub-0.24.0 scikit-image-0.14.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "argparse"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_spbZWK7CHq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cafbf24f-2dee-44ea-ada5-1101c62cb26e"
      },
      "source": [
        "import tensorflow\n",
        "import numpy as np\n",
        "tensorflow.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14TqM3dYQ2wk",
        "colab_type": "text"
      },
      "source": [
        "#### Navigate to the repo we downloaded\n",
        "We will run all our commands from this repo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvkvgyMmQxxk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "b7624afc-d685-4020-d23f-23620431cd65"
      },
      "source": [
        "!pwd\n",
        "import os\n",
        "os.chdir('/content/cs231n-emotiw')\n",
        "!pwd"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "/content/cs231n-emotiw\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qsmv0bdQJQp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "150b7d34-421a-421e-f0e5-edaf127e3371"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import src.preprocessors.preprocess_all_modes"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Video Preprocessor created with is_zip = True, video_folder = train-tiny.zip , label_file = Train_labels.txt , output_folder = train-tiny-local, output_file = train-tiny-local.zip\n",
            "Frames will be created with height = 320 , width = 480 , sample_every = 10\n",
            "Video Preprocessor created with is_zip = True, video_folder = train-tiny.zip , output_folder = train-tiny-faces, output_file = train-tiny-faces.zip\n",
            "Frames will be created with height = 320 , width = 480 , sample_every = 10\n",
            "Pose Preprocessor created with is_zip = True, is_test = False, video_frame_folder = val-tiny.zip , output_folder = val-tiny-pose, output_file = val-tiny-pose.zip\n",
            "Video Preprocessor created with is_zip = True, video_folder = train-tiny.zip , output_folder = train-tiny-audio, output_file = train-tiny-audio.zip\n",
            "Frames will be created with hop_size = 0.5\n",
            "Unzipping files to temp dir train-tiny-local_tmp...\n",
            "Finished unzipping files\n",
            "Found 50 videos\n",
            "Processing video 30/50 with name 321_15.mp4 and class 3 \n",
            "\n",
            "Processing video 20/50 with name 276_3.mp4 and class 2 \n",
            "\n",
            "Processing video 21/50 with name 276_8.mp4 and class 1 \n",
            "\n",
            "Processing video 19/50 with name 258_2.mp4 and class 2 \n",
            "\n",
            "Processing video 16/50 with name 217_15.mp4 and class 1 \n",
            "\n",
            "Processing video 14/50 with name 198_5.mp4 and class 3 \n",
            "\n",
            "Processing video 28/50 with name 303_41.mp4 and class 3 \n",
            "\n",
            "Processing video 10/50 with name 16_14.mp4 and class 1 \n",
            "\n",
            "Processing video 13/50 with name 197_12.mp4 and class 1 \n",
            "\n",
            "Processing video 9/50 with name 148_4.mp4 and class 3 \n",
            "\n",
            "Processing video 5/50 with name 119_8.mp4 and class 3 \n",
            "Processing video 15/50 with name 204_13.mp4 and class 3 \n",
            "\n",
            "Processing video 11/50 with name 188_15.mp4 and class 3 \n",
            "\n",
            "\n",
            "Processing video 29/50 with name 312_1.mp4 and class 2 \n",
            "\n",
            "Processing video 24/50 with name 281_2.mp4 and class 2 \n",
            "\n",
            "Processing video 1/50 with name 101_12.mp4 and class 3 \n",
            "\n",
            "Processing video 23/50 with name 280_12.mp4 and class 1 \n",
            "\n",
            "Processing video 26/50 with name 2_2.mp4 and class 3 \n",
            "\n",
            "Processing video 31/50 with name 321_31.mp4 and class 1 \n",
            "\n",
            "Processing video 22/50 with name 277_3.mp4 and class 2 \n",
            "\n",
            "Processing video 7/50 with name 133_2.mp4 and class 1 \n",
            "\n",
            "Processing video 2/50 with name 101_30.mp4 and class 1 \n",
            "\n",
            "Processing video 8/50 with name 140_1.mp4 and class 1 \n",
            "\n",
            "Processing video 25/50 with name 286_4.mp4 and class 2 \n",
            "\n",
            "Processing video 18/50 with name 220_6.mp4 and class 3 \n",
            "\n",
            "Processing video 27/50 with name 300_56.mp4 and class 3 \n",
            "Processing video 4/50 with name 112_5.mp4 and class 2 \n",
            "\n",
            "Processing video 3/50 with name 108_13.mp4 and class 3 \n",
            "\n",
            "\n",
            "Processing video 17/50 with name 217_3.mp4 and class 1 \n",
            "\n",
            "Processing video 12/50 with name 188_22.mp4 and class 3 \n",
            "\n",
            "Processing video 6/50 with name 122_1.mp4 and class 1 \n",
            "\n",
            "Processing video 32/50 with name 324_34.mp4 and class 2 \n",
            "\n",
            "Processing video 33/50 with name 324_56.mp4 and class 3 \n",
            "\n",
            "Processing video 35/50 with name 328_13.mp4 and class 3 \n",
            "\n",
            "Processing video 34/50 with name 324_96.mp4 and class 3 \n",
            "\n",
            "Processing video 36/50 with name 334_21.mp4 and class 3 \n",
            "\n",
            "Processing video 37/50 with name 33_20.mp4 and class 1 \n",
            "\n",
            "Processing video 39/50 with name 3_17.mp4 and class 3 \n",
            "\n",
            "Processing video 38/50 with name 34_9.mp4 and class 2 \n",
            "\n",
            "Processing video 40/50 with name 3_29.mp4 and class 3 \n",
            "\n",
            "Processing video 41/50 with name 41_18.mp4 and class 1 \n",
            "\n",
            "Processing video 42/50 with name 43_12.mp4 and class 1 \n",
            "\n",
            "Processing video 44/50 with name 61_15.mp4 and class 1 \n",
            "\n",
            "Processing video 43/50 with name 52_1.mp4 and class 2 \n",
            "\n",
            "Processing video 45/50 with name 64_5.mp4 and class 1 \n",
            "\n",
            "Processing video 46/50 with name 68_9.mp4 and class 1 \n",
            "\n",
            "Processing video 47/50 with name 69_30.mp4 and class 2 \n",
            "\n",
            "Processing video 48/50 with name 7_6.mp4 and class 1 \n",
            "\n",
            "Processing video 49/50 with name 80_1.mp4 and class 1 \n",
            "\n",
            "Processing video 50/50 with name 97_22.mp4 and class 3 \n",
            "\n",
            "***** Submitted all tasks *****\n",
            "***** Completed *****\n",
            "Starting to zip files to train-tiny-local.zip\n",
            "Done zipping files to train-tiny-local.zip\n",
            "Done!\n",
            "Unzipping files to temp dir train-tiny-faces_tmp...\n",
            "Finished unzipping files\n",
            "Found 50 videos\n",
            "Processing video 1/50 with name 281_2.mp4 \n",
            "\n",
            "Processing video 2/50 with name 303_41.mp4 \n",
            "\n",
            "Processing video 6/50 with name 321_15.mp4 \n",
            "\n",
            "Processing video 4/50 with name 101_12.mp4 \n",
            "\n",
            "Processing video 12/50 with name 61_15.mp4 \n",
            "\n",
            "Processing video 11/50 with name 52_1.mp4 \n",
            "\n",
            "Processing video 16/50 with name 188_22.mp4 \n",
            "\n",
            "Processing video 10/50 with name 69_30.mp4 \n",
            "\n",
            "Processing video 14/50 with name 280_12.mp4 \n",
            "\n",
            "Processing video 19/50 with name 33_20.mp4 \n",
            "\n",
            "Processing video 7/50 with name 3_17.mp4 \n",
            "\n",
            "Processing video 18/50 with name 198_5.mp4 \n",
            "\n",
            "Processing video 8/50 with name 324_34.mp4 \n",
            "\n",
            "Processing video 20/50 with name 41_18.mp4 \n",
            "\n",
            "Processing video 25/50 with name 324_56.mp4 \n",
            "\n",
            "Processing video 15/50 with name 220_6.mp4 \n",
            "\n",
            "Processing video 22/50 with name 148_4.mp4 \n",
            "\n",
            "Processing video 13/50 with name 197_12.mp4 \n",
            "\n",
            "Processing video 23/50 with name 324_96.mp4 \n",
            "\n",
            "Processing video 21/50 with name 300_56.mp4 \n",
            "\n",
            "Processing video 24/50 with name 101_30.mp4 \n",
            "\n",
            "Processing video 9/50 with name 34_9.mp4 \n",
            "\n",
            "Processing video 5/50 with name 108_13.mp4 \n",
            "\n",
            "Processing video 28/50 with name 68_9.mp4 \n",
            "\n",
            "Processing video 17/50 with name 97_22.mp4 \n",
            "\n",
            "Processing video 27/50 with name 7_6.mp4 \n",
            "\n",
            "Processing video 29/50 with name 133_2.mp4 \n",
            "\n",
            "Processing video 26/50 with name 16_14.mp4 \n",
            "\n",
            "Processing video 3/50 with name 277_3.mp4 \n",
            "\n",
            "Processing video 30/50 with name 321_31.mp4 \n",
            "\n",
            "Processing video 31/50 with name 276_3.mp4 \n",
            "\n",
            "Processing video 32/50 with name 217_3.mp4 \n",
            "\n",
            "Processing video 33/50 with name 286_4.mp4 \n",
            "\n",
            "Processing video 35/50 with name 119_8.mp4 \n",
            "\n",
            "Processing video 34/50 with name 204_13.mp4 \n",
            "\n",
            "Processing video 36/50 with name 112_5.mp4 \n",
            "\n",
            "Processing video 37/50 with name 43_12.mp4 \n",
            "\n",
            "Processing video 38/50 with name 122_1.mp4 \n",
            "\n",
            "Processing video 39/50 with name 334_21.mp4 \n",
            "\n",
            "Processing video 40/50 with name 140_1.mp4 \n",
            "\n",
            "Processing video 41/50 with name 188_15.mp4 \n",
            "\n",
            "Processing video 42/50 with name 217_15.mp4 \n",
            "\n",
            "Processing video 44/50 with name 64_5.mp4 \n",
            "\n",
            "Processing video 43/50 with name 3_29.mp4 \n",
            "\n",
            "Processing video 45/50 with name 80_1.mp4 \n",
            "\n",
            "Processing video 47/50 with name 2_2.mp4 \n",
            "\n",
            "Processing video 46/50 with name 312_1.mp4 \n",
            "\n",
            "Processing video 48/50 with name 276_8.mp4 \n",
            "\n",
            "Processing video 50/50 with name 328_13.mp4 \n",
            "\n",
            "Processing video 49/50 with name 258_2.mp4 \n",
            "\n",
            "***** Submitted all tasks *****\n",
            "***** Completed *****\n",
            "Starting to zip files to train-tiny-faces.zip\n",
            "Done zipping files to train-tiny-faces.zip\n",
            "Done!\n",
            "Unzipping files to temp dir val-tiny-pose_tmp...\n",
            "Finished unzipping files\n",
            "Starting to zip files to val-tiny-pose.zip\n",
            "Done zipping files to val-tiny-pose.zip\n",
            "Done!\n",
            "Unzipping files to temp dir train-tiny-audio_tmp...\n",
            "Finished unzipping files\n",
            "Moviepy - Running:\n",
            ">>> \"+ \" \".join(cmd)\n",
            "Moviepy - Command successful\n",
            "Reading file 101_12.mp4extracted_audio.wav ...\n",
            "Moviepy - Running:\n",
            ">>> \"+ \" \".join(cmd)\n",
            "Moviepy - Command successful\n",
            "Reading file 101_30.mp4extracted_audio.wav ...\n",
            "Moviepy - Running:\n",
            ">>> \"+ \" \".join(cmd)\n",
            "Moviepy - Command successful\n",
            "Reading file 108_13.mp4extracted_audio.wav ...\n",
            "Moviepy - Running:\n",
            ">>> \"+ \" \".join(cmd)\n",
            "Moviepy - Command successful\n",
            "Reading file 112_5.mp4extracted_audio.wav ...\n",
            "Moviepy - Running:\n",
            ">>> \"+ \" \".join(cmd)\n",
            "Moviepy - Command successful\n",
            "Reading file 119_8.mp4extracted_audio.wav ...\n",
            "Moviepy - Running:\n",
            ">>> \"+ \" \".join(cmd)\n",
            "Moviepy - Command successful\n",
            "Reading file 122_1.mp4extracted_audio.wav ...\n",
            "Moviepy - Running:\n",
            ">>> \"+ \" \".join(cmd)\n",
            "Moviepy - Command successful\n",
            "Reading file 133_2.mp4extracted_audio.wav ...\n",
            "Moviepy - Running:\n",
            ">>> \"+ \" \".join(cmd)\n",
            "Moviepy - Command successful\n",
            "Reading file 140_1.mp4extracted_audio.wav ...\n",
            "Moviepy - Running:\n",
            ">>> \"+ \" \".join(cmd)\n",
            "Moviepy - Command successful\n",
            "Reading file 148_4.mp4extracted_audio.wav ...\n",
            "Moviepy - Running:\n",
            ">>> \"+ \" \".join(cmd)\n",
            "Moviepy - Command successful\n",
            "Reading file 16_14.mp4extracted_audio.wav ...\n",
            "Moviepy - Running:\n",
            ">>> \"+ \" \".join(cmd)\n",
            "Moviepy - Command successful\n",
            "Reading file 188_15.mp4extracted_audio.wav ...\n",
            "Moviepy - Running:\n",
            ">>> \"+ \" \".join(cmd)\n",
            "Moviepy - Command successful\n",
            "Reading file 188_22.mp4extracted_audio.wav ...\n",
            "Moviepy - Running:\n",
            ">>> \"+ \" \".join(cmd)\n",
            "Moviepy - Command successful\n",
            "Reading file 197_12.mp4extracted_audio.wav ...\n",
            "Moviepy - Running:\n",
            ">>> \"+ \" \".join(cmd)\n",
            "Moviepy - Command successful\n",
            "Reading file 198_5.mp4extracted_audio.wav ...\n",
            "Moviepy - Running:\n",
            ">>> \"+ \" \".join(cmd)\n",
            "Moviepy - Command successful\n",
            "Reading file 204_13.mp4extracted_audio.wav ...\n",
            "Moviepy - Running:\n",
            ">>> \"+ \" \".join(cmd)\n",
            "Moviepy - Command successful\n",
            "Reading file 217_15.mp4extracted_audio.wav ...\n",
            "Moviepy - Running:\n",
            ">>> \"+ \" \".join(cmd)\n",
            "Moviepy - Command successful\n",
            "Reading file 217_3.mp4extracted_audio.wav ...\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1702: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "187/187 [==============================] - 7s 39ms/step\n",
            "(17, 11, 6144)\n",
            "Moviepy - Running:\n",
            ">>> \"+ \" \".join(cmd)\n",
            "Moviepy - Command successful\n",
            "Reading file 220_6.mp4extracted_audio.wav ...\n",
            "Moviepy - Running:\n",
            ">>> \"+ \" \".join(cmd)\n",
            "Moviepy - Command successful\n",
            "Reading file 258_2.mp4extracted_audio.wav ...\n",
            "Moviepy - Running:\n",
            ">>> \"+ \" \".join(cmd)\n",
            "Moviepy - Command successful\n",
            "Reading file 276_3.mp4extracted_audio.wav ...\n",
            "Moviepy - Running:\n",
            ">>> \"+ \" \".join(cmd)\n",
            "Moviepy - Command successful\n",
            "Reading file 276_8.mp4extracted_audio.wav ...\n",
            "Moviepy - Running:\n",
            ">>> \"+ \" \".join(cmd)\n",
            "Moviepy - Command successful\n",
            "Reading file 277_3.mp4extracted_audio.wav ...\n",
            "Moviepy - Running:\n",
            ">>> \"+ \" \".join(cmd)\n",
            "Moviepy - Command successful\n",
            "Reading file 280_12.mp4extracted_audio.wav ...\n",
            "Moviepy - Running:\n",
            ">>> \"+ \" \".join(cmd)\n",
            "Moviepy - Command successful\n",
            "Reading file 281_2.mp4extracted_audio.wav ...\n",
            "Moviepy - Running:\n",
            ">>> \"+ \" \".join(cmd)\n",
            "Moviepy - Command successful\n",
            "Reading file 286_4.mp4extracted_audio.wav ...\n",
            "Moviepy - Running:\n",
            ">>> \"+ \" \".join(cmd)\n",
            "Moviepy - Command successful\n",
            "Reading file 2_2.mp4extracted_audio.wav ...\n",
            "Moviepy - Running:\n",
            ">>> \"+ \" \".join(cmd)\n",
            "Moviepy - Command successful\n",
            "Reading file 300_56.mp4extracted_audio.wav ...\n",
            "Moviepy - Running:\n",
            ">>> \"+ \" \".join(cmd)\n",
            "Moviepy - Command successful\n",
            "Reading file 303_41.mp4extracted_audio.wav ...\n",
            "Moviepy - Running:\n",
            ">>> \"+ \" \".join(cmd)\n",
            "Moviepy - Command successful\n",
            "Reading file 312_1.mp4extracted_audio.wav ...\n",
            "Moviepy - Running:\n",
            ">>> \"+ \" \".join(cmd)\n",
            "Moviepy - Command successful\n",
            "Reading file 321_15.mp4extracted_audio.wav ...\n",
            "Moviepy - Running:\n",
            ">>> \"+ \" \".join(cmd)\n",
            "Moviepy - Command successful\n",
            "Reading file 321_31.mp4extracted_audio.wav ...\n",
            "Moviepy - Running:\n",
            ">>> \"+ \" \".join(cmd)\n",
            "Moviepy - Command successful\n",
            "Reading file 324_34.mp4extracted_audio.wav ...\n",
            "Moviepy - Running:\n",
            ">>> \"+ \" \".join(cmd)\n",
            "Moviepy - Command successful\n",
            "Reading file 324_56.mp4extracted_audio.wav ...\n",
            "Moviepy - Running:\n",
            ">>> \"+ \" \".join(cmd)\n",
            "Moviepy - Command successful\n",
            "Reading file 324_96.mp4extracted_audio.wav ...\n",
            "187/187 [==============================] - 1s 4ms/step\n",
            "(34, 11, 6144)\n",
            "Moviepy - Running:\n",
            ">>> \"+ \" \".join(cmd)\n",
            "Moviepy - Command successful\n",
            "Reading file 328_13.mp4extracted_audio.wav ...\n",
            "Moviepy - Running:\n",
            ">>> \"+ \" \".join(cmd)\n",
            "Moviepy - Command successful\n",
            "Reading file 334_21.mp4extracted_audio.wav ...\n",
            "Moviepy - Running:\n",
            ">>> \"+ \" \".join(cmd)\n",
            "Moviepy - Command successful\n",
            "Reading file 33_20.mp4extracted_audio.wav ...\n",
            "Moviepy - Running:\n",
            ">>> \"+ \" \".join(cmd)\n",
            "Moviepy - Command successful\n",
            "Reading file 34_9.mp4extracted_audio.wav ...\n",
            "Moviepy - Running:\n",
            ">>> \"+ \" \".join(cmd)\n",
            "Moviepy - Command successful\n",
            "Reading file 3_17.mp4extracted_audio.wav ...\n",
            "Moviepy - Running:\n",
            ">>> \"+ \" \".join(cmd)\n",
            "Moviepy - Command successful\n",
            "Reading file 3_29.mp4extracted_audio.wav ...\n",
            "Moviepy - Running:\n",
            ">>> \"+ \" \".join(cmd)\n",
            "Moviepy - Command successful\n",
            "Reading file 41_18.mp4extracted_audio.wav ...\n",
            "Moviepy - Running:\n",
            ">>> \"+ \" \".join(cmd)\n",
            "Moviepy - Command successful\n",
            "Reading file 43_12.mp4extracted_audio.wav ...\n",
            "Moviepy - Running:\n",
            ">>> \"+ \" \".join(cmd)\n",
            "Moviepy - Command successful\n",
            "Reading file 52_1.mp4extracted_audio.wav ...\n",
            "Moviepy - Running:\n",
            ">>> \"+ \" \".join(cmd)\n",
            "Moviepy - Command successful\n",
            "Reading file 61_15.mp4extracted_audio.wav ...\n",
            "Moviepy - Running:\n",
            ">>> \"+ \" \".join(cmd)\n",
            "Moviepy - Command successful\n",
            "Reading file 64_5.mp4extracted_audio.wav ...\n",
            "Moviepy - Running:\n",
            ">>> \"+ \" \".join(cmd)\n",
            "Moviepy - Command successful\n",
            "Reading file 68_9.mp4extracted_audio.wav ...\n",
            "Moviepy - Running:\n",
            ">>> \"+ \" \".join(cmd)\n",
            "Moviepy - Command successful\n",
            "Reading file 69_30.mp4extracted_audio.wav ...\n",
            "Moviepy - Running:\n",
            ">>> \"+ \" \".join(cmd)\n",
            "Moviepy - Command successful\n",
            "Reading file 7_6.mp4extracted_audio.wav ...\n",
            "Moviepy - Running:\n",
            ">>> \"+ \" \".join(cmd)\n",
            "Moviepy - Command successful\n",
            "Reading file 80_1.mp4extracted_audio.wav ...\n",
            "Moviepy - Running:\n",
            ">>> \"+ \" \".join(cmd)\n",
            "Moviepy - Command successful\n",
            "Reading file 97_22.mp4extracted_audio.wav ...\n",
            "176/176 [==============================] - 1s 6ms/step\n",
            "(50, 11, 6144)\n",
            "Starting to zip files to train-tiny-audio.zip\n",
            "Done zipping files to train-tiny-audio.zip\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vc0OOW4vVI7a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf openpose/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0_gfpBjXP6S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPXBx950Xd8z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e72c5a86-b8fc-4277-c413-251d39888155"
      },
      "source": [
        "import tensorflow\n",
        "print(tensorflow.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2JYVwaWXb_Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "ea007b1b-d41f-44c6-c755-61a823b656f9"
      },
      "source": [
        "!pwd\n",
        "import os\n",
        "os.chdir('/content/cs231n-emotiw')\n",
        "!pwd"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "/content/cs231n-emotiw\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOIbnIoH_AHV",
        "colab_type": "code",
        "outputId": "a683a8cd-ab5f-4417-841b-cfffc194507a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "from src.classifiers.audio_classifier import AudioClassifier\n",
        "audio_classifier = AudioClassifier('/content/cs231n-emotiw/train-tiny-audio/' , model_location='/content/cs231n-emotiw/models/OPENL3_audio_api_train_test-1-500-epochs-0.5_hop--BEST_MODEL-w-VAL--1e-6-lr-0.2-dropout-512-feat-map-batch-norm-3-cnn-layers.h5' , is_zip=False , label_path='/content/cs231n-emotiw/Train_labels.txt', is_test=False)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AudioClassifier created with is_zip = False, audio_folder = /content/cs231n-emotiw/train-tiny-audio/ , is_test = False , model_location = /content/cs231n-emotiw/models/OPENL3_audio_api_train_test-1-500-epochs-0.5_hop--BEST_MODEL-w-VAL--1e-6-lr-0.2-dropout-512-feat-map-batch-norm-3-cnn-layers.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmCJJq2rGI4v",
        "colab_type": "code",
        "outputId": "46c2fcf2-ea8d-4173-faef-4bd437951b79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "audio_classifier.predict()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Skipping unzipping files as input is a folder\n",
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.7352549 , 0.10368147, 0.16106369],\n",
              "       [0.58754665, 0.18988699, 0.22256641],\n",
              "       [0.10893717, 0.0722108 , 0.818852  ],\n",
              "       [0.13373221, 0.18219595, 0.6840718 ],\n",
              "       [0.17264253, 0.04676025, 0.7805972 ],\n",
              "       [0.26388448, 0.54826874, 0.18784681],\n",
              "       [0.7234918 , 0.13596755, 0.14054067],\n",
              "       [0.69436437, 0.13573948, 0.16989619],\n",
              "       [0.29626924, 0.08265976, 0.62107104],\n",
              "       [0.40677324, 0.32726896, 0.2659578 ],\n",
              "       [0.07144767, 0.06616978, 0.86238253],\n",
              "       [0.08527348, 0.12475839, 0.7899681 ],\n",
              "       [0.66314876, 0.09379585, 0.24305543],\n",
              "       [0.4389831 , 0.24717052, 0.3138464 ],\n",
              "       [0.06467322, 0.09840969, 0.83691704],\n",
              "       [0.5473322 , 0.21291876, 0.23974906],\n",
              "       [0.553305  , 0.29760084, 0.14909416],\n",
              "       [0.15859866, 0.067486  , 0.77391535],\n",
              "       [0.2882756 , 0.5272712 , 0.18445314],\n",
              "       [0.1846266 , 0.6846615 , 0.13071193],\n",
              "       [0.274708  , 0.5770294 , 0.14826262],\n",
              "       [0.1936001 , 0.6693539 , 0.13704605],\n",
              "       [0.561387  , 0.20225877, 0.23635425],\n",
              "       [0.19991882, 0.61609644, 0.18398474],\n",
              "       [0.1460827 , 0.7588004 , 0.09511688],\n",
              "       [0.29414046, 0.29462448, 0.41123506],\n",
              "       [0.14094009, 0.60447574, 0.25458425],\n",
              "       [0.07954449, 0.03948785, 0.8809676 ],\n",
              "       [0.47632614, 0.08616155, 0.4375123 ],\n",
              "       [0.11658555, 0.10305802, 0.7803564 ],\n",
              "       [0.11575671, 0.12699538, 0.7572479 ],\n",
              "       [0.14887379, 0.70061725, 0.15050896],\n",
              "       [0.56289256, 0.26866448, 0.168443  ],\n",
              "       [0.29165465, 0.4799121 , 0.22843324],\n",
              "       [0.09694425, 0.06212404, 0.84093165],\n",
              "       [0.06969394, 0.0872157 , 0.8430904 ],\n",
              "       [0.64502764, 0.16718303, 0.18778937],\n",
              "       [0.2846728 , 0.56777793, 0.1475493 ],\n",
              "       [0.17872152, 0.08506475, 0.73621374],\n",
              "       [0.3606042 , 0.19309177, 0.44630402],\n",
              "       [0.54698735, 0.28520995, 0.16780266],\n",
              "       [0.6863832 , 0.11068454, 0.20293231],\n",
              "       [0.23721968, 0.4844369 , 0.27834344],\n",
              "       [0.31449112, 0.4924473 , 0.19306166],\n",
              "       [0.21770684, 0.6320066 , 0.15028653],\n",
              "       [0.50203854, 0.30389568, 0.19406581],\n",
              "       [0.14928776, 0.69702154, 0.15369071],\n",
              "       [0.62907004, 0.12261669, 0.24831326],\n",
              "       [0.69164836, 0.09498324, 0.21336834],\n",
              "       [0.08253837, 0.0804165 , 0.8370451 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYT4nS36GOl4",
        "colab_type": "code",
        "outputId": "bb056862-5813-457e-81d3-7d1e8d66b5dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "audio_classifier.evaluate()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Skipping unzipping files as input is a folder\n",
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.7059 - accuracy: 0.7600\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7059367895126343, 0.7599999904632568]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xwIeRF_x40m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(mp4_dir , train_target_path , model_list= [model,] , model_paths=[\"\",] , num_models = 1 , mode=\"soft\" , complexFusion=False):\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  Notes: \n",
        "\n",
        "  All file preprocessing will occur in this function.\n",
        "\n",
        "\n",
        "  Inputs\n",
        "  \n",
        "  * mp4_train_dir - The directory of .mp4 file paths that the model will make predictions from.\n",
        "  * train_target_path - The target path. Should be in .txt format.\n",
        "  * A list of pretrained models that will be used in the ensemble during prediction\n",
        "\n",
        "\n",
        "  Outputs \n",
        "\n",
        "  * An array of size (M) where M is the number of samples\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  assert len(model_list) == num_models\n",
        "  assert len(model_paths) == num_models\n",
        "\n",
        "  all_model_predictions = []\n",
        "  X_list = []\n",
        "\n",
        "  counter = 0\n",
        "  \n",
        "                            \n",
        "\n",
        "  for model in models:\n",
        "\n",
        "    model.load_model(model_paths[counter])\n",
        "\n",
        "\n",
        "    X = X_list[counter]\n",
        "    \n",
        "   \n",
        "\n",
        "    all_model_predictions.append(model.predict(dir=\"video path/*.mp4\" , X=X)) # Predict returns an (M , 3) array\n",
        "    \n",
        "    counter += 1\n",
        "\n",
        "  all_model_predictions = np.asarray(all_model_predictions , dtype='float32') # (num_models , M , 3)\n",
        "\n",
        "\n",
        "  assert mode in [\"soft\" , \"hard\"]\n",
        "\n",
        "  if mode == \"soft\":\n",
        "\n",
        "    \n",
        "    # Take the average of each \n",
        "\n",
        "    predictions = np.mean(all_model_predictions , axis=0)\n",
        "\n",
        "    predictions = np.argmax(predictions , axis = 1)\n",
        "\n",
        "    return predictions  # (M,) in the domain [0,1,2]\n",
        "\n",
        "  # TODO: Majority vote\n",
        "\n",
        "  positive_hard = np.argmax(positive_arr , axis=1) # ()\n",
        "\n",
        "\n",
        "\n",
        "  return predictions "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TJCeo420Zx8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(predictions, targets):\n",
        "\n",
        "  # TO DO: Add evaluate code here\n",
        "\n",
        "  \"\"\"\n",
        "  Inputs\n",
        "  \n",
        "  * predictions np array of shape M where M is the number of samples\n",
        "  * target array of shape M where M is the number of samples\n",
        "\n",
        "\n",
        "  Outputs \n",
        "\n",
        "  * Model accuracy scalar \n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  assert len(targets) == len(predictions)\n",
        "\n",
        "  incorrect = np.count_nonzero(predictions - targets)\n",
        "\n",
        "  acc = (targets.shape[0] - incorrect) / targets.shape[0]\n",
        "\n",
        "  return acc\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}